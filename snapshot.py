import streamlit as st
import pandas as pd
import time
import os
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from datetime import datetime, timedelta

# ================= âš™ï¸ æ ¸å¿ƒé…ç½® =================
POLL_INTERVAL = 10       # æ‰«æé¢‘ç‡ï¼š10ç§’ (æ—¢å¿«åˆå®‰å…¨)
MAX_HISTORY_MINUTES = 30 # æœ€å¤§è®°å¿†æ—¶é•¿ï¼š30åˆ†é’Ÿ
CACHE_FILE = "cyberpunk_data_pool.csv" # æœ¬åœ°æŒä¹…åŒ–æ–‡ä»¶

# ================= ğŸ¨ ç§‘æŠ€é£ UI æ³¨å…¥ =================
st.set_page_config(layout="wide", page_title="OPINION // CORE MONITOR")

# æ³¨å…¥è‡ªå®šä¹‰ CSS (èµ›åšæœ‹å…‹é£æ ¼)
st.markdown("""
<style>
    /* å…¨å±€èƒŒæ™¯å¾®è°ƒ */
    .stApp {
        background-color: #0e1117;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    h1 {
        font-family: 'Courier New', monospace;
        text-transform: uppercase;
        color: #00ff41; /* é»‘å®¢ç»¿ */
        text-shadow: 0 0 10px #00ff41;
        border-bottom: 2px solid #00ff41;
        padding-bottom: 10px;
    }
    
    h3 {
        font-family: 'Courier New', monospace;
        color: #e0e0e0;
        border-left: 5px solid #ff00ff; /* èµ›åšç²‰ */
        padding-left: 10px;
    }

    /* è¡¨æ ¼å®¹å™¨æ ·å¼ */
    .stDataFrame {
        border: 1px solid #333;
        box-shadow: 0 0 15px rgba(0, 255, 65, 0.1);
    }

    /* çŠ¶æ€æ æ ·å¼ */
    .status-text {
        font-family: 'Courier New', monospace;
        color: #00bfff;
        font-size: 0.8em;
    }
</style>
""", unsafe_allow_html=True)

# ================= ğŸ•·ï¸ çˆ¬è™«æ ¸å¿ƒ =================
def fetch_raw_data():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-dev-shm-usage") # äº‘ç«¯é˜²å´©
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-gpu")
    
    driver = webdriver.Chrome(options=chrome_options)
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
    })
    
    url = "https://opinionanalytics.xyz/activity"
    new_items = []
    
    try:
        driver.set_page_load_timeout(15)
        driver.get(url)
        time.sleep(2) # æé€Ÿç­‰å¾…
        
        rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
        current_scrape_time = datetime.now()
        
        for row in rows:
            cols = row.find_elements(By.TAG_NAME, "td")
            if len(cols) < 8: continue
            try:
                side = cols[1].text
                market = cols[3].text
                event = cols[4].text
                amount = float(cols[6].text.replace('$', '').replace(',', ''))
                # åŸå§‹æ—¶é—´å­—ç¬¦ä¸² (ç½‘é¡µä¸Šçš„ "10 mins ago" æˆ–å…·ä½“æ—¶é—´)
                raw_time_str = cols[9].text 
                
                # ç”Ÿæˆå”¯ä¸€ID
                unique_key = f"{event}_{market}_{side}_{amount}_{raw_time_str}"
                
                new_items.append({
                    "unique_key": unique_key,
                    "Event": event,
                    "Market": market,
                    "Side": side,
                    "Amount": amount,
                    "ScrapeTime": current_scrape_time # è®°å½•æŠ“å–æ—¶é—´ä½œä¸ºåŸºå‡†
                })
            except:
                continue
    except Exception as e:
        print(f"Scrape Error: {e}")
    finally:
        driver.quit()
        
    return pd.DataFrame(new_items)

# ================= ğŸ’¾ æ•°æ®å¼•æ“ (æ»šåŠ¨çª—å£) =================

# åˆå§‹åŒ–æˆ–åŠ è½½å†å²æ•°æ®
if 'master_pool' not in st.session_state:
    if os.path.exists(CACHE_FILE):
        try:
            df = pd.read_csv(CACHE_FILE)
            df['ScrapeTime'] = pd.to_datetime(df['ScrapeTime'])
            st.session_state.master_pool = df
        except:
            st.session_state.master_pool = pd.DataFrame()
    else:
        st.session_state.master_pool = pd.DataFrame()

if 'last_update_str' not in st.session_state:
    st.session_state.last_update_str = "SYSTEM_BOOT..."

def process_data_pool(new_df):
    """
    1. åˆå¹¶æ–°æ•°æ®
    2. å»é‡
    3. æ¸…ç†è¶…è¿‡30åˆ†é’Ÿçš„æ—§æ•°æ®
    4. ä¿å­˜å¿«ç…§
    """
    pool = st.session_state.master_pool
    
    if not new_df.empty:
        # åˆå¹¶
        pool = pd.concat([pool, new_df])
        # å»é‡ (ä¿ç•™æœ€æ–°çš„)
        pool = pool.drop_duplicates(subset=['unique_key'], keep='last')
    
    # æ¸…ç†æ—§æ•°æ® (åªä¿ç•™æœ€è¿‘ MAX_HISTORY_MINUTES)
    if not pool.empty:
        cutoff_time = datetime.now() - timedelta(minutes=MAX_HISTORY_MINUTES)
        pool = pool[pool['ScrapeTime'] > cutoff_time]
    
    st.session_state.master_pool = pool
    # å­˜ç›˜
    pool.to_csv(CACHE_FILE, index=False)
    return pool

def get_ranking(minutes_window):
    """
    ä»ä¸»æ± ä¸­åˆ‡ç‰‡ï¼Œè®¡ç®—æ’å
    """
    pool = st.session_state.master_pool
    if pool.empty:
        return pd.DataFrame()
    
    # ç­›é€‰æ—¶é—´çª—å£
    cutoff = datetime.now() - timedelta(minutes=minutes_window)
    subset = pool[pool['ScrapeTime'] > cutoff]
    
    if subset.empty:
        return pd.DataFrame()
        
    # èšåˆ
    ranking = subset.groupby(['Event', 'Market', 'Side']).agg(
        Count=('unique_key', 'count'),
        Total=('Amount', 'sum')
    ).reset_index()
    
    # æ’åº
    ranking = ranking.sort_values(by=['Count', 'Total'], ascending=[False, False])
    ranking.index = range(1, len(ranking) + 1)
    return ranking

def style_ranking(df):
    """ç»™è¡¨æ ¼ä¸Šè‰²"""
    if df.empty: return df
    
    # é¢œè‰²é€»è¾‘
    def highlight_side(val):
        color = '#00ff41' if ('BUY' in val or 'YES' in val) else '#ff0055'
        return f'color: {color}; font-weight: bold; text-shadow: 0 0 5px {color};'
    
    return df.style.applymap(highlight_side, subset=['Side']).format({"Total": "${:,.0f}"})

# ================= ğŸ–¥ï¸ æŒ‡æŒ¥èˆ±ç•Œé¢ =================

st.title("OPINION // ANALYTICS_HUB")
st.markdown("<div class='status-text'>System Status: ONLINE | Mode: CONTINUOUS_SCAN | Target: opinionanalytics.xyz</div>", unsafe_allow_html=True)

st.divider()

# ä¸‰æ å¸ƒå±€
col1, col2, col3 = st.columns(3)

# å ä½ç¬¦ (é˜²æ­¢é¡µé¢è·³åŠ¨ï¼Œå…ˆå å‘)
with col1:
    st.markdown("### âš¡ 1 MINUTE (BURST)")
    c1_placeholder = st.empty()
with col2:
    st.markdown("### ğŸŒŠ 10 MINUTES (FLOW)")
    c2_placeholder = st.empty()
with col3:
    st.markdown("### ğŸ’ 30 MINUTES (TREND)")
    c3_placeholder = st.empty()

# åº•éƒ¨çŠ¶æ€æ¡
st.divider()
status_log = st.empty()

# ================= ğŸ”„ ä¸»å¾ªç¯ =================
while True:
    # 1. æŠ“å–ä¸æ›´æ–°æ•°æ®æ± 
    status_log.markdown(f"`[{datetime.now().strftime('%H:%M:%S')}] SCANNING NETWORK...`")
    
    new_batch = fetch_raw_data()
    process_data_pool(new_batch) # æ›´æ–°ä¸»æ•°æ®æ± 
    
    current_time = datetime.now().strftime('%H:%M:%S')
    
    # 2. ç”Ÿæˆä¸‰ä»½æŠ¥è¡¨
    df_1m = get_ranking(1)
    df_10m = get_ranking(10)
    df_30m = get_ranking(30)
    
    # 3. æ¸²æŸ“ UI (å¸¦è¿›åº¦æ¡é…ç½®)
    def render_table(placeholder, df, max_count):
        if df.empty:
            placeholder.info("NO_DATA_SIGNAL")
        else:
            placeholder.dataframe(
                style_ranking(df),
                use_container_width=True,
                height=500, # ç»Ÿä¸€é«˜åº¦
                column_config={
                    "Count": st.column_config.ProgressColumn(
                        format="%d",
                        min_value=0,
                        max_value=int(max_count * 1.2) if max_count > 0 else 10,
                    ),
                    "Event": st.column_config.TextColumn(width="small"),
                    "Market": st.column_config.TextColumn(width="small")
                }
            )
            
    # è®¡ç®—å„è‡ªçš„æœ€å¤§å€¼ç”¨äºè¿›åº¦æ¡æ¯”ä¾‹
    max_1m = df_1m['Count'].max() if not df_1m.empty else 0
    max_10m = df_10m['Count'].max() if not df_10m.empty else 0
    max_30m = df_30m['Count'].max() if not df_30m.empty else 0
    
    render_table(c1_placeholder, df_1m, max_1m)
    render_table(c2_placeholder, df_10m, max_10m)
    render_table(c3_placeholder, df_30m, max_30m)
    
    # 4. çŠ¶æ€æ›´æ–°
    pool_size = len(st.session_state.master_pool)
    status_log.markdown(f"`[{current_time}] SYNC_COMPLETE | DATA_POOL_SIZE: {pool_size} | NEXT_SCAN: {POLL_INTERVAL}s`")
    
    # 5. çŸ­æš‚ç­‰å¾… (ä¸æ˜¾ç¤ºå€’è®¡æ—¶ï¼Œé™é»˜ç­‰å¾…)
    time.sleep(POLL_INTERVAL)
